{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "\n",
      "0: 320x640 1 person, 439.9ms\n",
      "Speed: 3.1ms preprocess, 439.9ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 3 chairs, 329.1ms\n",
      "Speed: 1.9ms preprocess, 329.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 3 chairs, 349.3ms\n",
      "Speed: 0.0ms preprocess, 349.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 390.7ms\n",
      "Speed: 0.0ms preprocess, 390.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 526.5ms\n",
      "Speed: 0.0ms preprocess, 526.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 chairs, 448.2ms\n",
      "Speed: 5.1ms preprocess, 448.2ms inference, 13.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 3 chairs, 466.8ms\n",
      "Speed: 6.2ms preprocess, 466.8ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 chairs, 468.3ms\n",
      "Speed: 1.5ms preprocess, 468.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 1 tv, 662.8ms\n",
      "Speed: 0.0ms preprocess, 662.8ms inference, 17.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 652.1ms\n",
      "Speed: 11.3ms preprocess, 652.1ms inference, 7.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 437.3ms\n",
      "Speed: 4.0ms preprocess, 437.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 668.6ms\n",
      "Speed: 0.0ms preprocess, 668.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 tv, 1 laptop, 539.6ms\n",
      "Speed: 15.6ms preprocess, 539.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 1 tv, 500.6ms\n",
      "Speed: 0.0ms preprocess, 500.6ms inference, 15.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 tv, 535.2ms\n",
      "Speed: 0.0ms preprocess, 535.2ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 499.7ms\n",
      "Speed: 0.0ms preprocess, 499.7ms inference, 8.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 1 chair, 361.2ms\n",
      "Speed: 0.0ms preprocess, 361.2ms inference, 16.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 1 chair, 1 tv, 662.0ms\n",
      "Speed: 9.5ms preprocess, 662.0ms inference, 16.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 797.7ms\n",
      "Speed: 18.4ms preprocess, 797.7ms inference, 10.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 606.2ms\n",
      "Speed: 13.1ms preprocess, 606.2ms inference, 6.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 chair, 1 tv, 337.5ms\n",
      "Speed: 5.0ms preprocess, 337.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 persons, 1 chair, 1 tv, 360.7ms\n",
      "Speed: 1.8ms preprocess, 360.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 2 chairs, 448.1ms\n",
      "Speed: 0.0ms preprocess, 448.1ms inference, 16.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 chairs, 434.4ms\n",
      "Speed: 0.0ms preprocess, 434.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 2 chairs, 488.9ms\n",
      "Speed: 0.0ms preprocess, 488.9ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 chair, 906.1ms\n",
      "Speed: 11.5ms preprocess, 906.1ms inference, 12.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 860.1ms\n",
      "Speed: 15.3ms preprocess, 860.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 2 chairs, 1 couch, 398.1ms\n",
      "Speed: 0.0ms preprocess, 398.1ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 305.9ms\n",
      "Speed: 0.0ms preprocess, 305.9ms inference, 13.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 2 chairs, 1 tv, 472.5ms\n",
      "Speed: 0.0ms preprocess, 472.5ms inference, 12.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 2 chairs, 583.2ms\n",
      "Speed: 11.9ms preprocess, 583.2ms inference, 15.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 chair, 600.3ms\n",
      "Speed: 15.6ms preprocess, 600.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 533.0ms\n",
      "Speed: 0.0ms preprocess, 533.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 388.6ms\n",
      "Speed: 6.7ms preprocess, 388.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 chair, 487.4ms\n",
      "Speed: 0.0ms preprocess, 487.4ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     35\u001b[0m frame\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(frame,(\u001b[38;5;241m1020\u001b[39m,\u001b[38;5;241m500\u001b[39m))\n\u001b[1;32m---> 37\u001b[0m results\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m&\u001b[39m\u001b[38;5;241m0xFF\u001b[39m\u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\model.py:439\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py:248\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 248\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:425\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 425\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    129\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:231\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 231\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:231\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 231\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:341\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;124;03m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "\n",
    "model=YOLO('yolov8s.pt')\n",
    "\n",
    "\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)\n",
    "        \n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "my_file = open(\"coco.txt\", \"r\")\n",
    "data = my_file.read()\n",
    "class_list = data.split(\"\\n\")\n",
    "print(class_list)\n",
    "count=0\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 3 != 0:\n",
    "        continue\n",
    "    frame=cv2.resize(frame,(1020,500))\n",
    "\n",
    "    results=model.predict(frame)\n",
    "           \n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1)&0xFF== ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "\n",
      "0: 320x640 (no detections), 338.2ms\n",
      "Speed: 6.3ms preprocess, 338.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[139, 125]\n",
      "\n",
      "0: 320x640 1 person, 331.5ms\n",
      "Speed: 11.0ms preprocess, 331.5ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 337.4ms\n",
      "Speed: 7.5ms preprocess, 337.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[549, 235]\n",
      "\n",
      "0: 320x640 2 persons, 334.6ms\n",
      "Speed: 3.5ms preprocess, 334.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[465, 63]\n",
      "[465, 61]\n",
      "\n",
      "0: 320x640 4 persons, 331.4ms\n",
      "Speed: 1.1ms preprocess, 331.4ms inference, 5.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[468, 1]\n",
      "\n",
      "0: 320x640 2 persons, 414.5ms\n",
      "Speed: 4.5ms preprocess, 414.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 persons, 343.9ms\n",
      "Speed: 1.5ms preprocess, 343.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[455, 26]\n",
      "\n",
      "0: 320x640 3 persons, 331.0ms\n",
      "Speed: 7.0ms preprocess, 331.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[456, 4]\n",
      "[456, 4]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 315.2ms\n",
      "Speed: 3.4ms preprocess, 315.2ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 311.7ms\n",
      "Speed: 8.9ms preprocess, 311.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 319.7ms\n",
      "Speed: 5.0ms preprocess, 319.7ms inference, 6.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 372.8ms\n",
      "Speed: 0.5ms preprocess, 372.8ms inference, 7.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 363.3ms\n",
      "Speed: 13.7ms preprocess, 363.3ms inference, 5.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 truck, 351.2ms\n",
      "Speed: 6.8ms preprocess, 351.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 355.6ms\n",
      "Speed: 7.6ms preprocess, 355.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 396.6ms\n",
      "Speed: 6.2ms preprocess, 396.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[612, 40]\n",
      "[615, 43]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 362.2ms\n",
      "Speed: 5.8ms preprocess, 362.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[800, 100]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 348.8ms\n",
      "Speed: 3.9ms preprocess, 348.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 337.7ms\n",
      "Speed: 5.2ms preprocess, 337.7ms inference, 6.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 349.7ms\n",
      "Speed: 4.9ms preprocess, 349.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 355.8ms\n",
      "Speed: 5.0ms preprocess, 355.8ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 345.9ms\n",
      "Speed: 4.9ms preprocess, 345.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 330.3ms\n",
      "Speed: 4.0ms preprocess, 330.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 309.6ms\n",
      "Speed: 6.0ms preprocess, 309.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 329.0ms\n",
      "Speed: 0.0ms preprocess, 329.0ms inference, 13.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 340.0ms\n",
      "Speed: 6.4ms preprocess, 340.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 424.9ms\n",
      "Speed: 4.6ms preprocess, 424.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 331.6ms\n",
      "Speed: 0.0ms preprocess, 331.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 327.3ms\n",
      "Speed: 1.7ms preprocess, 327.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 321.0ms\n",
      "Speed: 10.5ms preprocess, 321.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 323.4ms\n",
      "Speed: 2.7ms preprocess, 323.4ms inference, 7.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 334.3ms\n",
      "Speed: 0.0ms preprocess, 334.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 312.1ms\n",
      "Speed: 0.0ms preprocess, 312.1ms inference, 10.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 334.7ms\n",
      "Speed: 1.1ms preprocess, 334.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 347.5ms\n",
      "Speed: 0.5ms preprocess, 347.5ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 348.0ms\n",
      "Speed: 6.4ms preprocess, 348.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 325.7ms\n",
      "Speed: 8.5ms preprocess, 325.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 304.9ms\n",
      "Speed: 5.8ms preprocess, 304.9ms inference, 9.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 330.7ms\n",
      "Speed: 2.7ms preprocess, 330.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 325.9ms\n",
      "Speed: 8.1ms preprocess, 325.9ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 333.7ms\n",
      "Speed: 3.8ms preprocess, 333.7ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 328.6ms\n",
      "Speed: 4.9ms preprocess, 328.6ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 334.4ms\n",
      "Speed: 3.3ms preprocess, 334.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 336.2ms\n",
      "Speed: 9.5ms preprocess, 336.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 332.5ms\n",
      "Speed: 2.0ms preprocess, 332.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 315.1ms\n",
      "Speed: 4.8ms preprocess, 315.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 320.8ms\n",
      "Speed: 5.4ms preprocess, 320.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 321.4ms\n",
      "Speed: 2.0ms preprocess, 321.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 traffic light, 377.8ms\n",
      "Speed: 5.1ms preprocess, 377.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 368.1ms\n",
      "Speed: 4.7ms preprocess, 368.1ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 332.7ms\n",
      "Speed: 6.7ms preprocess, 332.7ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 333.2ms\n",
      "Speed: 5.5ms preprocess, 333.2ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 1 truck, 324.1ms\n",
      "Speed: 6.1ms preprocess, 324.1ms inference, 10.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 persons, 3 cars, 1 truck, 308.3ms\n",
      "Speed: 4.9ms preprocess, 308.3ms inference, 15.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 truck, 317.1ms\n",
      "Speed: 4.4ms preprocess, 317.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 331.5ms\n",
      "Speed: 5.2ms preprocess, 331.5ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 persons, 3 cars, 319.2ms\n",
      "Speed: 8.0ms preprocess, 319.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 307.5ms\n",
      "Speed: 8.6ms preprocess, 307.5ms inference, 13.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 1 truck, 348.6ms\n",
      "Speed: 3.9ms preprocess, 348.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 1 truck, 340.7ms\n",
      "Speed: 2.7ms preprocess, 340.7ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 cars, 1 truck, 329.4ms\n",
      "Speed: 3.9ms preprocess, 329.4ms inference, 10.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 334.7ms\n",
      "Speed: 3.5ms preprocess, 334.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 336.2ms\n",
      "Speed: 1.0ms preprocess, 336.2ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 truck, 371.7ms\n",
      "Speed: 0.0ms preprocess, 371.7ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 314.6ms\n",
      "Speed: 3.7ms preprocess, 314.6ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 326.2ms\n",
      "Speed: 4.4ms preprocess, 326.2ms inference, 11.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 309.9ms\n",
      "Speed: 5.9ms preprocess, 309.9ms inference, 11.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 331.8ms\n",
      "Speed: 8.5ms preprocess, 331.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 318.1ms\n",
      "Speed: 10.0ms preprocess, 318.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 322.3ms\n",
      "Speed: 5.3ms preprocess, 322.3ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 376.9ms\n",
      "Speed: 0.0ms preprocess, 376.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 321.4ms\n",
      "Speed: 3.6ms preprocess, 321.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 321.9ms\n",
      "Speed: 5.6ms preprocess, 321.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 328.8ms\n",
      "Speed: 0.0ms preprocess, 328.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 1 truck, 323.9ms\n",
      "Speed: 6.4ms preprocess, 323.9ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 328.4ms\n",
      "Speed: 5.7ms preprocess, 328.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 323.2ms\n",
      "Speed: 5.9ms preprocess, 323.2ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 358.3ms\n",
      "Speed: 5.5ms preprocess, 358.3ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 336.4ms\n",
      "Speed: 4.2ms preprocess, 336.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 316.7ms\n",
      "Speed: 4.2ms preprocess, 316.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 4 cars, 319.8ms\n",
      "Speed: 10.7ms preprocess, 319.8ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 338.8ms\n",
      "Speed: 4.8ms preprocess, 338.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 314.1ms\n",
      "Speed: 4.7ms preprocess, 314.1ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 320.1ms\n",
      "Speed: 10.4ms preprocess, 320.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 323.0ms\n",
      "Speed: 4.2ms preprocess, 323.0ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 308.5ms\n",
      "Speed: 4.1ms preprocess, 308.5ms inference, 15.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 326.1ms\n",
      "Speed: 12.3ms preprocess, 326.1ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 332.2ms\n",
      "Speed: 8.3ms preprocess, 332.2ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 306.8ms\n",
      "Speed: 7.1ms preprocess, 306.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 326.5ms\n",
      "Speed: 3.2ms preprocess, 326.5ms inference, 8.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 322.8ms\n",
      "Speed: 2.4ms preprocess, 322.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 380.6ms\n",
      "Speed: 6.5ms preprocess, 380.6ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 362.8ms\n",
      "Speed: 3.4ms preprocess, 362.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 349.9ms\n",
      "Speed: 5.2ms preprocess, 349.9ms inference, 6.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 321.0ms\n",
      "Speed: 9.4ms preprocess, 321.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 310.9ms\n",
      "Speed: 3.6ms preprocess, 310.9ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 336.9ms\n",
      "Speed: 2.6ms preprocess, 336.9ms inference, 9.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 326.1ms\n",
      "Speed: 4.0ms preprocess, 326.1ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 329.2ms\n",
      "Speed: 4.7ms preprocess, 329.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 324.4ms\n",
      "Speed: 4.4ms preprocess, 324.4ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 316.1ms\n",
      "Speed: 3.0ms preprocess, 316.1ms inference, 10.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 321.0ms\n",
      "Speed: 5.5ms preprocess, 321.0ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 314.1ms\n",
      "Speed: 4.7ms preprocess, 314.1ms inference, 13.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 342.3ms\n",
      "Speed: 6.6ms preprocess, 342.3ms inference, 12.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 335.6ms\n",
      "Speed: 4.5ms preprocess, 335.6ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 3 cars, 330.1ms\n",
      "Speed: 6.1ms preprocess, 330.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 395.3ms\n",
      "Speed: 0.0ms preprocess, 395.3ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 321.4ms\n",
      "Speed: 4.7ms preprocess, 321.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[368, 99]\n",
      "[359, 79]\n",
      "\n",
      "0: 320x640 3 cars, 359.7ms\n",
      "Speed: 7.5ms preprocess, 359.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[359, 79]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 367.8ms\n",
      "Speed: 4.9ms preprocess, 367.8ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[377, 26]\n",
      "\n",
      "0: 320x640 3 cars, 360.8ms\n",
      "Speed: 8.0ms preprocess, 360.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[377, 26]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 351.0ms\n",
      "Speed: 5.3ms preprocess, 351.0ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 349.5ms\n",
      "Speed: 5.3ms preprocess, 349.5ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 485.0ms\n",
      "Speed: 4.8ms preprocess, 485.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 351.0ms\n",
      "Speed: 3.5ms preprocess, 351.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 353.7ms\n",
      "Speed: 8.3ms preprocess, 353.7ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[438, 83]\n",
      "[438, 87]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 348.3ms\n",
      "Speed: 6.1ms preprocess, 348.3ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[437, 192]\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 353.9ms\n",
      "Speed: 7.7ms preprocess, 353.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[431, 373]\n",
      "\n",
      "0: 320x640 3 cars, 353.5ms\n",
      "Speed: 0.0ms preprocess, 353.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[460, 151]\n",
      "\n",
      "0: 320x640 3 cars, 1 parking meter, 408.5ms\n",
      "Speed: 5.1ms preprocess, 408.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 airplane, 360.6ms\n",
      "Speed: 7.8ms preprocess, 360.6ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 348.0ms\n",
      "Speed: 3.9ms preprocess, 348.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 1 airplane, 334.1ms\n",
      "Speed: 1.0ms preprocess, 334.1ms inference, 7.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 354.0ms\n",
      "Speed: 8.1ms preprocess, 354.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 cars, 348.3ms\n",
      "Speed: 5.7ms preprocess, 348.3ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "[894, 5]\n",
      "\n",
      "0: 320x640 2 cars, 385.9ms\n",
      "Speed: 5.8ms preprocess, 385.9ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 364.4ms\n",
      "Speed: 11.5ms preprocess, 364.4ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Detected vehicles: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "\n",
    "model=YOLO('yolov8s.pt')\n",
    "\n",
    "\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)\n",
    "        \n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB',RGB)\n",
    "\n",
    "cap=cv2.VideoCapture(\"Traffic IP Camera video (1).mp4\")\n",
    "\n",
    "my_file = open(\"coco.txt\", \"r\")\n",
    "data = my_file.read()\n",
    "class_list = data.split(\"\\n\")\n",
    "print(class_list)\n",
    "count=0\n",
    "detected_vehicles = 0\n",
    "area = [(712,11),(252,491),(1011,494),(1017,2)]\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 3 != 0:\n",
    "        continue\n",
    "    frame=cv2.resize(frame,(1020,500))\n",
    "    \n",
    "\n",
    "    results=model.predict(frame)\n",
    "    a=results[0].boxes.data\n",
    "    px = pd.DataFrame(a).astype('float')\n",
    "    for index,row in px.iterrows():\n",
    "        x1=int(row[0])\n",
    "        y1=int(row[1])\n",
    "        x2=int(row[2])\n",
    "        y2=int(row[3])\n",
    "        d=int(row[5])\n",
    "        c=class_list[d]\n",
    "        if 'car' in c:\n",
    "            result = cv2.pointPolygonTest(np.array(area,np.int32),((x1,y2)),False)\n",
    "            if result >= 0:\n",
    "                cv2.rectangle(frame,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "                cv2.circle(frame,(x1,y2),4,(2555,0,0),-1)\n",
    "                cv2.putText(frame,str(c),(x1,y1),cv2.FONT_HERSHEY_COMPLEX,(0.5),(255,255,255))\n",
    "    cv2.polylines(frame,[np.array(area,np.int32)],True,(255,0,255),2)     \n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    print(f\"Detected vehicles: {detected_vehicles}\")\n",
    "    if cv2.waitKey(1)&0xFF== ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "\n",
      "0: 320x640 (no detections), 405.4ms\n",
      "Speed: 0.0ms preprocess, 405.4ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 667.1ms\n",
      "Speed: 10.8ms preprocess, 667.1ms inference, 8.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 575.9ms\n",
      "Speed: 8.0ms preprocess, 575.9ms inference, 13.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 persons, 444.1ms\n",
      "Speed: 3.6ms preprocess, 444.1ms inference, 15.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 4 persons, 428.0ms\n",
      "Speed: 6.9ms preprocess, 428.0ms inference, 14.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 persons, 469.7ms\n",
      "Speed: 3.4ms preprocess, 469.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 3 persons, 444.7ms\n",
      "Speed: 5.7ms preprocess, 444.7ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 3 persons, 734.6ms\n",
      "Speed: 6.3ms preprocess, 734.6ms inference, 8.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 515.8ms\n",
      "Speed: 8.5ms preprocess, 515.8ms inference, 7.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 397.9ms\n",
      "Speed: 8.4ms preprocess, 397.9ms inference, 7.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 473.3ms\n",
      "Speed: 4.3ms preprocess, 473.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 412.4ms\n",
      "Speed: 5.6ms preprocess, 412.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 382.9ms\n",
      "Speed: 7.4ms preprocess, 382.9ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 truck, 565.6ms\n",
      "Speed: 6.9ms preprocess, 565.6ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 426.2ms\n",
      "Speed: 6.3ms preprocess, 426.2ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 419.7ms\n",
      "Speed: 5.3ms preprocess, 419.7ms inference, 9.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 431.9ms\n",
      "Speed: 5.5ms preprocess, 431.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 449.5ms\n",
      "Speed: 4.4ms preprocess, 449.5ms inference, 7.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 445.2ms\n",
      "Speed: 4.0ms preprocess, 445.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 397.8ms\n",
      "Speed: 3.6ms preprocess, 397.8ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[299, 430]\n",
      "[298, 424]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 349.8ms\n",
      "Speed: 5.5ms preprocess, 349.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[338, 365]\n",
      "[338, 364]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 328.0ms\n",
      "Speed: 8.0ms preprocess, 328.0ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[334, 294]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 365.4ms\n",
      "Speed: 7.7ms preprocess, 365.4ms inference, 12.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[328, 296]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 341.7ms\n",
      "Speed: 8.0ms preprocess, 341.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[314, 291]\n",
      "[314, 291]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 345.7ms\n",
      "Speed: 2.4ms preprocess, 345.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[315, 286]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 322.6ms\n",
      "Speed: 4.0ms preprocess, 322.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[316, 286]\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 318.7ms\n",
      "Speed: 5.6ms preprocess, 318.7ms inference, 16.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[318, 285]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 309.9ms\n",
      "Speed: 2.8ms preprocess, 309.9ms inference, 15.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 326.7ms\n",
      "Speed: 5.5ms preprocess, 326.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[324, 290]\n",
      "[325, 291]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 345.2ms\n",
      "Speed: 0.0ms preprocess, 345.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[360, 331]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 332.2ms\n",
      "Speed: 4.6ms preprocess, 332.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[158, 280]\n",
      "[158, 281]\n",
      "\n",
      "0: 320x640 3 cars, 352.0ms\n",
      "Speed: 6.5ms preprocess, 352.0ms inference, 9.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[68, 304]\n",
      "\n",
      "0: 320x640 3 cars, 362.5ms\n",
      "Speed: 4.5ms preprocess, 362.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[83, 322]\n",
      "[82, 324]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 336.3ms\n",
      "Speed: 5.4ms preprocess, 336.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[74, 289]\n",
      "[80, 288]\n",
      "\n",
      "0: 320x640 3 cars, 343.2ms\n",
      "Speed: 4.1ms preprocess, 343.2ms inference, 6.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[183, 256]\n",
      "\n",
      "0: 320x640 3 cars, 344.6ms\n",
      "Speed: 4.0ms preprocess, 344.6ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[179, 330]\n",
      "\n",
      "0: 320x640 3 cars, 343.9ms\n",
      "Speed: 3.5ms preprocess, 343.9ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[131, 312]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 345.2ms\n",
      "Speed: 4.3ms preprocess, 345.2ms inference, 8.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[136, 306]\n",
      "\n",
      "0: 320x640 3 cars, 352.8ms\n",
      "Speed: 3.8ms preprocess, 352.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[181, 294]\n",
      "[185, 294]\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 345.7ms\n",
      "Speed: 6.6ms preprocess, 345.7ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[287, 400]\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 342.1ms\n",
      "Speed: 5.0ms preprocess, 342.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[305, 398]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 326.3ms\n",
      "Speed: 0.0ms preprocess, 326.3ms inference, 8.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 334.7ms\n",
      "Speed: 4.3ms preprocess, 334.7ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[234, 398]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 318.4ms\n",
      "Speed: 5.7ms preprocess, 318.4ms inference, 13.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[320, 213]\n",
      "[332, 185]\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 328.5ms\n",
      "Speed: 4.9ms preprocess, 328.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[404, 16]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 459.8ms\n",
      "Speed: 3.7ms preprocess, 459.8ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[410, 14]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 337.3ms\n",
      "Speed: 4.5ms preprocess, 337.3ms inference, 6.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[410, 0]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 327.0ms\n",
      "Speed: 7.8ms preprocess, 327.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 traffic light, 332.8ms\n",
      "Speed: 8.7ms preprocess, 332.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 316.3ms\n",
      "Speed: 4.8ms preprocess, 316.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 361.8ms\n",
      "Speed: 7.6ms preprocess, 361.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 323.2ms\n",
      "Speed: 7.8ms preprocess, 323.2ms inference, 11.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 1 truck, 349.3ms\n",
      "Speed: 4.8ms preprocess, 349.3ms inference, 11.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[498, 7]\n",
      "\n",
      "0: 320x640 3 persons, 3 cars, 1 truck, 341.0ms\n",
      "Speed: 4.4ms preprocess, 341.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 truck, 355.0ms\n",
      "Speed: 3.6ms preprocess, 355.0ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 367.3ms\n",
      "Speed: 6.2ms preprocess, 367.3ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 3 persons, 3 cars, 336.4ms\n",
      "Speed: 5.9ms preprocess, 336.4ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 363.2ms\n",
      "Speed: 5.4ms preprocess, 363.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 1 truck, 329.1ms\n",
      "Speed: 7.4ms preprocess, 329.1ms inference, 7.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 1 truck, 323.8ms\n",
      "Speed: 4.4ms preprocess, 323.8ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 2 cars, 1 truck, 323.9ms\n",
      "Speed: 4.0ms preprocess, 323.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 314.4ms\n",
      "Speed: 3.6ms preprocess, 314.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 314.8ms\n",
      "Speed: 3.8ms preprocess, 314.8ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 truck, 331.2ms\n",
      "Speed: 1.9ms preprocess, 331.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "\n",
      "0: 320x640 3 cars, 342.7ms\n",
      "Speed: 5.9ms preprocess, 342.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[473, 145]\n",
      "[473, 151]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 421.6ms\n",
      "Speed: 3.7ms preprocess, 421.6ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[440, 350]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 379.1ms\n",
      "Speed: 4.5ms preprocess, 379.1ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[439, 360]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 333.7ms\n",
      "Speed: 3.8ms preprocess, 333.7ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "set()\n",
      "[439, 361]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 329.8ms\n",
      "Speed: 4.9ms preprocess, 329.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5}\n",
      "[460, 479]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 329.3ms\n",
      "Speed: 5.9ms preprocess, 329.3ms inference, 8.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 372.4ms\n",
      "Speed: 7.5ms preprocess, 372.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 344.5ms\n",
      "Speed: 6.1ms preprocess, 344.5ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 338.9ms\n",
      "Speed: 5.9ms preprocess, 338.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 324.4ms\n",
      "Speed: 0.0ms preprocess, 324.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 1 truck, 321.7ms\n",
      "Speed: 5.0ms preprocess, 321.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 316.0ms\n",
      "Speed: 5.0ms preprocess, 316.0ms inference, 10.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 341.4ms\n",
      "Speed: 7.8ms preprocess, 341.4ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 326.8ms\n",
      "Speed: 4.8ms preprocess, 326.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 351.2ms\n",
      "Speed: 3.0ms preprocess, 351.2ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 338.2ms\n",
      "Speed: 6.6ms preprocess, 338.2ms inference, 6.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "[346, 399]\n",
      "\n",
      "0: 320x640 4 cars, 392.6ms\n",
      "Speed: 5.3ms preprocess, 392.6ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "[335, 387]\n",
      "\n",
      "0: 320x640 3 cars, 342.1ms\n",
      "Speed: 1.0ms preprocess, 342.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 331.5ms\n",
      "Speed: 3.2ms preprocess, 331.5ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 344.2ms\n",
      "Speed: 3.0ms preprocess, 344.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 344.9ms\n",
      "Speed: 2.0ms preprocess, 344.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 331.4ms\n",
      "Speed: 5.6ms preprocess, 331.4ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 408.5ms\n",
      "Speed: 10.5ms preprocess, 408.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 328.0ms\n",
      "Speed: 4.5ms preprocess, 328.0ms inference, 6.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 349.1ms\n",
      "Speed: 3.0ms preprocess, 349.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 329.1ms\n",
      "Speed: 7.0ms preprocess, 329.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 342.4ms\n",
      "Speed: 1.0ms preprocess, 342.4ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 334.0ms\n",
      "Speed: 3.3ms preprocess, 334.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 362.4ms\n",
      "Speed: 4.2ms preprocess, 362.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 373.0ms\n",
      "Speed: 3.7ms preprocess, 373.0ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 336.4ms\n",
      "Speed: 10.3ms preprocess, 336.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 355.6ms\n",
      "Speed: 5.6ms preprocess, 355.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 361.2ms\n",
      "Speed: 5.6ms preprocess, 361.2ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 355.7ms\n",
      "Speed: 6.4ms preprocess, 355.7ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 353.1ms\n",
      "Speed: 4.9ms preprocess, 353.1ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 346.2ms\n",
      "Speed: 3.4ms preprocess, 346.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 350.2ms\n",
      "Speed: 5.8ms preprocess, 350.2ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 354.1ms\n",
      "Speed: 4.2ms preprocess, 354.1ms inference, 6.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 331.9ms\n",
      "Speed: 4.8ms preprocess, 331.9ms inference, 12.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 349.0ms\n",
      "Speed: 5.4ms preprocess, 349.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 348.8ms\n",
      "Speed: 7.5ms preprocess, 348.8ms inference, 16.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 331.4ms\n",
      "Speed: 4.7ms preprocess, 331.4ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 361.2ms\n",
      "Speed: 7.1ms preprocess, 361.2ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 435.3ms\n",
      "Speed: 7.2ms preprocess, 435.3ms inference, 6.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 339.0ms\n",
      "Speed: 6.3ms preprocess, 339.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 338.9ms\n",
      "Speed: 7.5ms preprocess, 338.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 340.7ms\n",
      "Speed: 4.9ms preprocess, 340.7ms inference, 11.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 331.8ms\n",
      "Speed: 5.4ms preprocess, 331.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 328.8ms\n",
      "Speed: 1.0ms preprocess, 328.8ms inference, 10.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 327.2ms\n",
      "Speed: 2.0ms preprocess, 327.2ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 337.8ms\n",
      "Speed: 5.8ms preprocess, 337.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 323.9ms\n",
      "Speed: 3.9ms preprocess, 323.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 325.9ms\n",
      "Speed: 5.5ms preprocess, 325.9ms inference, 10.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 341.1ms\n",
      "Speed: 5.0ms preprocess, 341.1ms inference, 5.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 3 cars, 330.6ms\n",
      "Speed: 5.4ms preprocess, 330.6ms inference, 11.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "[234, 373]\n",
      "\n",
      "0: 320x640 3 cars, 1 parking meter, 351.5ms\n",
      "Speed: 6.9ms preprocess, 351.5ms inference, 7.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "[240, 365]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 airplane, 379.3ms\n",
      "Speed: 5.6ms preprocess, 379.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 363.5ms\n",
      "Speed: 4.1ms preprocess, 363.5ms inference, 12.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 1 airplane, 317.5ms\n",
      "Speed: 6.1ms preprocess, 317.5ms inference, 10.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "{19, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "\n",
    "\n",
    "model=YOLO('yolov8s.pt')\n",
    "\n",
    "\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)\n",
    "        \n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB',RGB)\n",
    "\n",
    "cap=cv2.VideoCapture(\"Traffic IP Camera video (1).mp4\")\n",
    "\n",
    "my_file = open(\"coco.txt\", \"r\")\n",
    "data = my_file.read()\n",
    "class_list = data.split(\"\\n\")\n",
    "print(class_list)\n",
    "count=0\n",
    "tracker = Tracker()\n",
    "\n",
    "car_entering = {}\n",
    "count_car = set()\n",
    "area = [(267,429),(226,491),(1011,494),(951,447)]\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 3 != 0:\n",
    "        continue\n",
    "    frame=cv2.resize(frame,(1020,500))\n",
    "    \n",
    "\n",
    "    results=model.predict(frame)\n",
    "    a=results[0].boxes.data\n",
    "    px = pd.DataFrame(a).astype('float')\n",
    "    list = []\n",
    "    for index,row in px.iterrows():\n",
    "        x1=int(row[0])\n",
    "        y1=int(row[1])\n",
    "        x2=int(row[2])\n",
    "        y2=int(row[3])\n",
    "        d=int(row[5])\n",
    "        c=class_list[d]\n",
    "        '''if 'car' in c:\n",
    "            result = cv2.pointPolygonTest(np.array(area,np.int32),((x1,y2)),False)\n",
    "            if result >= 0:\n",
    "                cv2.rectangle(frame,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "                cv2.circle(frame,(x1,y2),4,(2555,0,0),-1)\n",
    "                cv2.putText(frame,str(c),(x1,y1),cv2.FONT_HERSHEY_COMPLEX,(0.5),(255,255,255))'''\n",
    "        if 'car' in c:\n",
    "           list.append([x1,y1,x2,y2])\n",
    "    bbox_id = tracker.update(list)\n",
    "    for bbox in bbox_id:\n",
    "        x3,y3,x4,y4,id = bbox\n",
    "        result=cv2.pointPolygonTest(np.array(area,np.int32),((x4,y4)),False)\n",
    "        if result >= 0:\n",
    "            car_entering[id]=(x4,y4)\n",
    "            cv2.rectangle(frame,(x3,y3),(x4,y4),(0,255,0),2)\n",
    "            cv2.circle(frame,(x4,y4),5,(2555,0,0),-1)\n",
    "            cv2.putText(frame,str(id),(x3,y3),cv2.FONT_HERSHEY_COMPLEX,(0.5),(255,255,255))\n",
    "            count_car.add(id)\n",
    "        \n",
    "    cv2.polylines(frame,[np.array(area,np.int32)],True,(255,0,255),2) \n",
    "    print(len(count_car))    \n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1)&0xFF== ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
